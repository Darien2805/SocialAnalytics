{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lab 7 (Reddit)\n",
    "\n",
    "This script connect to Reddit API and crawls posts based on search terms.\n",
    "\n",
    "Ref: http://www.storybench.org/how-to-scrape-reddit-with-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Andy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from elasticsearch import Elasticsearch\n",
    "import nltk\n",
    "from nltk import tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "from operator import itemgetter\n",
    "import math\n",
    "import numpy as np\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reddit = praw.Reddit(client_id='', \\\n",
    "                     client_secret='', \\\n",
    "                     user_agent='', \\\n",
    "                     username='', \\\n",
    "                     password='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit = reddit.subreddit('hackathon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_subreddit = subreddit.new()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_dict = { \"title\":[], \\\n",
    "                \"score\":[], \\\n",
    "                \"id\":[], \"url\":[], \\\n",
    "                \"comms_num\": [], \\\n",
    "                \"created\": [], \\\n",
    "                \"body\":[]}\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for submission in subreddit.new(limit=1000):\n",
    "    # get the details of the post\n",
    "    topics_dict[\"title\"].append(submission.title.lower())\n",
    "    topics_dict[\"score\"].append(submission.score)\n",
    "    topics_dict[\"id\"].append(submission.id)\n",
    "    topics_dict[\"url\"].append(submission.url)\n",
    "    topics_dict[\"comms_num\"].append(submission.num_comments)\n",
    "    topics_dict[\"body\"].append(submission.selftext.lower())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateBOW(wordset,l_doc):\n",
    "  tf_diz = dict.fromkeys(wordset,0)\n",
    "  for word in l_doc:\n",
    "      tf_diz[word]=l_doc.count(word)\n",
    "  return tf_diz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine title and body\n",
    "keywordbags = [x + y for x, y in zip(topics_dict[\"title\"], topics_dict[\"body\"])]\n",
    "# remove punctuation\n",
    "keywordbags = [x.replace('.', '').replace(',', '').replace('?', '').replace('!', '').replace('(', '').replace(')', '').replace(';', '').replace(':', '') for x in keywordbags]\n",
    "# split into words\n",
    "keywordbags = [x.split() for x in keywordbags]\n",
    "# strip all words\n",
    "for each_list in keywordbags:\n",
    "  for i in range(len(each_list)):\n",
    "    each_list[i] = each_list[i].strip('[').strip('\"').strip('{').strip(']').strip('}').strip(\"'\")\n",
    "    \n",
    "# lowercase all words\n",
    "keywordbags = [[y.lower() for y in x] for x in keywordbags]\n",
    "# remove empty strings\n",
    "keywordbags = [[y for y in x if y] for x in keywordbags]\n",
    "# remove stop words\n",
    "stopwordz = ['the', 'a', 'an', 'and', 'or', 'but', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'will', 'would', 'shall', 'should', 'can', 'could', 'may', 'might', 'must', 'to', 'of', 'in', 'for', 'on', 'at', 'by', 'from', 'with', 'about', 'as', 'into', 'like', 'through', 'after', 'over', 'between', 'out', 'against', 'during', 'without', 'before', 'under', 'around', 'down', 'off', 'above', 'below', 'up', 'into', 'out', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now', '&', 'your', 'ourselves', 'hers', 'between', 'yourself', 'but', 'again', 'there', 'about', 'once', 'during', 'out', 'very', 'having', 'with', 'they', 'own', 'an', 'be', 'some', 'for', 'do', 'its', 'yours', 'such', 'into', 'of', 'most', 'itself', 'other', 'off', 'is', 's', 'am', 'or', 'who', 'as', 'from', 'him', 'each', 'the', 'themselves', 'until', 'below', 'are', 'we', 'these', 'your', 'his', 'through', 'don', 'nor', 'me', 'were', 'her', 'more', 'himself', 'this', 'down', 'should', 'our', 'their', 'while', 'above', 'both', 'up', 'to', 'ours', 'had', 'she', 'all', 'no', 'when', 'at', 'any', 'before', 'them', 'same', 'and', 'been', 'have', 'in', 'will', 'on', 'does', 'yourselves', 'then', 'that', 'because', 'what', 'over', 'why', 'so', 'can', 'did', 'not', 'now', 'under', 'he', 'you', 'herself', 'has', 'just', 'where', 'too', 'only', 'myself', 'which', 'those', 'i', 'after', 'few', 'whom', 't', 'being', 'if', 'theirs', 'my', 'against', 'a', 'by', 'doing', 'it', 'how', 'further', 'was', 'here', 'than', 'us', '-', '--', '*', \"get\", \"it's\"]\n",
    "keywordbags = [[x for x in y if x not in stopwordz] for y in keywordbags]\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "keywordbags = [[x for x in y if x not in stop_words] for y in keywordbags]\n",
    "\n",
    "# remove words words that contains http or www\n",
    "keywordbags = [[x for x in y if 'http' not in x] for y in keywordbags]\n",
    "keywordbags = [[x for x in y if 'www' not in x] for y in keywordbags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = [item for sublist in keywordbags for item in sublist]\n",
    "df = pd.DataFrame(all_words, columns=['word'])\n",
    "df.to_csv('all_words.csv', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = Elasticsearch(\"http://localhost:9200\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andy\\AppData\\Local\\Temp\\ipykernel_12496\\3378907868.py:6: DeprecationWarning: Passing transport options in the API method is deprecated. Use 'Elasticsearch.options()' instead.\n",
      "  es.indices.delete(index='reddit', ignore=[400, 404])\n"
     ]
    },
    {
     "ename": "ConnectionError",
     "evalue": "Connection error caused by: ConnectionError(Connection error caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x0000027DEB6CD3C0>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Andy\\OneDrive - Singapore Management University\\Desktop\\SA\\scrapy-hackathon\\webscrape\\reddit\\reddit_hackathon.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Andy/OneDrive%20-%20Singapore%20Management%20University/Desktop/SA/scrapy-hackathon/webscrape/reddit/reddit_hackathon.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# put a new index with mappings \"mappings\": {\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Andy/OneDrive%20-%20Singapore%20Management%20University/Desktop/SA/scrapy-hackathon/webscrape/reddit/reddit_hackathon.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39m# \"properties\": {\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Andy/OneDrive%20-%20Singapore%20Management%20University/Desktop/SA/scrapy-hackathon/webscrape/reddit/reddit_hackathon.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39m#   \"mytext\":{\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Andy/OneDrive%20-%20Singapore%20Management%20University/Desktop/SA/scrapy-hackathon/webscrape/reddit/reddit_hackathon.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m         \u001b[39m# \"type\":\"text\",\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Andy/OneDrive%20-%20Singapore%20Management%20University/Desktop/SA/scrapy-hackathon/webscrape/reddit/reddit_hackathon.ipynb#X14sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         \u001b[39m# \"fielddata\": true\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Andy/OneDrive%20-%20Singapore%20Management%20University/Desktop/SA/scrapy-hackathon/webscrape/reddit/reddit_hackathon.ipynb#X14sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m es\u001b[39m.\u001b[39;49mindices\u001b[39m.\u001b[39;49mdelete(index\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mreddit\u001b[39;49m\u001b[39m'\u001b[39;49m, ignore\u001b[39m=\u001b[39;49m[\u001b[39m400\u001b[39;49m, \u001b[39m404\u001b[39;49m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Andy/OneDrive%20-%20Singapore%20Management%20University/Desktop/SA/scrapy-hackathon/webscrape/reddit/reddit_hackathon.ipynb#X14sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# create a new index with mappings\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Andy/OneDrive%20-%20Singapore%20Management%20University/Desktop/SA/scrapy-hackathon/webscrape/reddit/reddit_hackathon.ipynb#X14sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m es\u001b[39m.\u001b[39mindices\u001b[39m.\u001b[39mcreate(index\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mreddit\u001b[39m\u001b[39m'\u001b[39m, body\u001b[39m=\u001b[39m{\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Andy/OneDrive%20-%20Singapore%20Management%20University/Desktop/SA/scrapy-hackathon/webscrape/reddit/reddit_hackathon.ipynb#X14sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmappings\u001b[39m\u001b[39m\"\u001b[39m: {\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Andy/OneDrive%20-%20Singapore%20Management%20University/Desktop/SA/scrapy-hackathon/webscrape/reddit/reddit_hackathon.ipynb#X14sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mproperties\u001b[39m\u001b[39m\"\u001b[39m: {\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Andy/OneDrive%20-%20Singapore%20Management%20University/Desktop/SA/scrapy-hackathon/webscrape/reddit/reddit_hackathon.ipynb#X14sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     }\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Andy/OneDrive%20-%20Singapore%20Management%20University/Desktop/SA/scrapy-hackathon/webscrape/reddit/reddit_hackathon.ipynb#X14sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m })\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\elasticsearch\\_sync\\client\\utils.py:414\u001b[0m, in \u001b[0;36m_rewrite_parameters.<locals>.wrapper.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    411\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[0;32m    412\u001b[0m             \u001b[39mpass\u001b[39;00m\n\u001b[1;32m--> 414\u001b[0m \u001b[39mreturn\u001b[39;00m api(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\elasticsearch\\_sync\\client\\indices.py:690\u001b[0m, in \u001b[0;36mIndicesClient.delete\u001b[1;34m(self, index, allow_no_indices, error_trace, expand_wildcards, filter_path, human, ignore_unavailable, master_timeout, pretty, timeout)\u001b[0m\n\u001b[0;32m    688\u001b[0m     __query[\u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m timeout\n\u001b[0;32m    689\u001b[0m __headers \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39maccept\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mapplication/json\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[1;32m--> 690\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mperform_request(  \u001b[39m# type: ignore[return-value]\u001b[39;49;00m\n\u001b[0;32m    691\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mDELETE\u001b[39;49m\u001b[39m\"\u001b[39;49m, __path, params\u001b[39m=\u001b[39;49m__query, headers\u001b[39m=\u001b[39;49m__headers\n\u001b[0;32m    692\u001b[0m )\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\elasticsearch\\_sync\\client\\_base.py:390\u001b[0m, in \u001b[0;36mNamespacedClient.perform_request\u001b[1;34m(self, method, path, params, headers, body)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mperform_request\u001b[39m(\n\u001b[0;32m    380\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    381\u001b[0m     method: \u001b[39mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    388\u001b[0m     \u001b[39m# Use the internal clients .perform_request() implementation\u001b[39;00m\n\u001b[0;32m    389\u001b[0m     \u001b[39m# so we take advantage of their transport options.\u001b[39;00m\n\u001b[1;32m--> 390\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_client\u001b[39m.\u001b[39;49mperform_request(\n\u001b[0;32m    391\u001b[0m         method, path, params\u001b[39m=\u001b[39;49mparams, headers\u001b[39m=\u001b[39;49mheaders, body\u001b[39m=\u001b[39;49mbody\n\u001b[0;32m    392\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\elasticsearch\\_sync\\client\\_base.py:286\u001b[0m, in \u001b[0;36mBaseClient.perform_request\u001b[1;34m(self, method, path, params, headers, body)\u001b[0m\n\u001b[0;32m    283\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    284\u001b[0m     target \u001b[39m=\u001b[39m path\n\u001b[1;32m--> 286\u001b[0m meta, resp_body \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransport\u001b[39m.\u001b[39;49mperform_request(\n\u001b[0;32m    287\u001b[0m     method,\n\u001b[0;32m    288\u001b[0m     target,\n\u001b[0;32m    289\u001b[0m     headers\u001b[39m=\u001b[39;49mrequest_headers,\n\u001b[0;32m    290\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[0;32m    291\u001b[0m     request_timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request_timeout,\n\u001b[0;32m    292\u001b[0m     max_retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_max_retries,\n\u001b[0;32m    293\u001b[0m     retry_on_status\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_retry_on_status,\n\u001b[0;32m    294\u001b[0m     retry_on_timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_retry_on_timeout,\n\u001b[0;32m    295\u001b[0m     client_meta\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_client_meta,\n\u001b[0;32m    296\u001b[0m )\n\u001b[0;32m    298\u001b[0m \u001b[39m# HEAD with a 404 is returned as a normal response\u001b[39;00m\n\u001b[0;32m    299\u001b[0m \u001b[39m# since this is used as an 'exists' functionality.\u001b[39;00m\n\u001b[0;32m    300\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mHEAD\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m meta\u001b[39m.\u001b[39mstatus \u001b[39m==\u001b[39m \u001b[39m404\u001b[39m) \u001b[39mand\u001b[39;00m (\n\u001b[0;32m    301\u001b[0m     \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m meta\u001b[39m.\u001b[39mstatus \u001b[39m<\u001b[39m \u001b[39m299\u001b[39m\n\u001b[0;32m    302\u001b[0m     \u001b[39mand\u001b[39;00m (\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    306\u001b[0m     )\n\u001b[0;32m    307\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\elastic_transport\\_transport.py:329\u001b[0m, in \u001b[0;36mTransport.perform_request\u001b[1;34m(self, method, target, body, headers, max_retries, retry_on_status, retry_on_timeout, request_timeout, client_meta)\u001b[0m\n\u001b[0;32m    327\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m    328\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 329\u001b[0m     meta, raw_data \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39;49mperform_request(\n\u001b[0;32m    330\u001b[0m         method,\n\u001b[0;32m    331\u001b[0m         target,\n\u001b[0;32m    332\u001b[0m         body\u001b[39m=\u001b[39;49mrequest_body,\n\u001b[0;32m    333\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest_headers,\n\u001b[0;32m    334\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[0;32m    335\u001b[0m     )\n\u001b[0;32m    336\u001b[0m     _logger\u001b[39m.\u001b[39minfo(\n\u001b[0;32m    337\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m%s\u001b[39;00m\u001b[39m [status:\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m duration:\u001b[39m\u001b[39m%.3f\u001b[39;00m\u001b[39ms]\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    338\u001b[0m         \u001b[39m%\u001b[39m (\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    344\u001b[0m         )\n\u001b[0;32m    345\u001b[0m     )\n\u001b[0;32m    347\u001b[0m     \u001b[39mif\u001b[39;00m method \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mHEAD\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\elastic_transport\\_node\\_http_urllib3.py:199\u001b[0m, in \u001b[0;36mUrllib3HttpNode.perform_request\u001b[1;34m(self, method, target, body, headers, request_timeout)\u001b[0m\n\u001b[0;32m    191\u001b[0m         err \u001b[39m=\u001b[39m \u001b[39mConnectionError\u001b[39;00m(\u001b[39mstr\u001b[39m(e), errors\u001b[39m=\u001b[39m(e,))\n\u001b[0;32m    192\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_request(\n\u001b[0;32m    193\u001b[0m         method\u001b[39m=\u001b[39mmethod,\n\u001b[0;32m    194\u001b[0m         target\u001b[39m=\u001b[39mtarget,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    197\u001b[0m         exception\u001b[39m=\u001b[39merr,\n\u001b[0;32m    198\u001b[0m     )\n\u001b[1;32m--> 199\u001b[0m     \u001b[39mraise\u001b[39;00m err \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m    201\u001b[0m meta \u001b[39m=\u001b[39m ApiResponseMeta(\n\u001b[0;32m    202\u001b[0m     node\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig,\n\u001b[0;32m    203\u001b[0m     duration\u001b[39m=\u001b[39mduration,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    206\u001b[0m     headers\u001b[39m=\u001b[39mresponse_headers,\n\u001b[0;32m    207\u001b[0m )\n\u001b[0;32m    208\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_request(\n\u001b[0;32m    209\u001b[0m     method\u001b[39m=\u001b[39mmethod,\n\u001b[0;32m    210\u001b[0m     target\u001b[39m=\u001b[39mtarget,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    214\u001b[0m     response\u001b[39m=\u001b[39mdata,\n\u001b[0;32m    215\u001b[0m )\n",
      "\u001b[1;31mConnectionError\u001b[0m: Connection error caused by: ConnectionError(Connection error caused by: NewConnectionError(<urllib3.connection.HTTPConnection object at 0x0000027DEB6CD3C0>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it))"
     ]
    }
   ],
   "source": [
    "# put a new index with mappings \"mappings\": {\n",
    "    # \"properties\": {\n",
    "    #   \"mytext\":{\n",
    "        # \"type\":\"text\",\n",
    "        # \"fielddata\": true\n",
    "es.indices.delete(index='reddit', ignore=[400, 404])\n",
    "# create a new index with mappings\n",
    "es.indices.create(index='reddit', body={\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"keyword\":{\n",
    "                \"type\":\"text\",\n",
    "                \"fielddata\": True\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "})\n",
    "\n",
    "# insert keywordbags into elasticsearch\n",
    "elastic_id = 1\n",
    "for i in range(len(keywordbags)):\n",
    "    for j in range(len(keywordbags[i])):\n",
    "        # create a dictionary for each document\n",
    "        doc = {}\n",
    "        doc['keyword'] = keywordbags[i][j]\n",
    "        doc['created'] = dt.datetime.now()\n",
    "        # insert into elasticsearch\n",
    "        es.index(index='reddit', id=elastic_id, document=doc)\n",
    "        elastic_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove reddit.tf-idf indices\n",
    "es.indices.delete(index='reddit.tf_idfscore', ignore=[400, 404])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
